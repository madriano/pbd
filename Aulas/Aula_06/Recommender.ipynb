{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2021/22**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Recommender Systems\n",
    "This lecture is about recommender systems (or recommendation systems). In the meantime, we highlight the usefulness of Spark SQL, particularly when it relates to persistent tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Spark SQL\n",
    "\n",
    "As mentioned in the initial lectures, Spark SQL is a Spark module for structured data processing. It works alongside the APIs of DataFrame and Dataset and it is responsible for performing extra optimizations. We can also execute SQL queries and reading data from various files formats an Hive tables. (Apache Hive can manage large datasets residing in distributed storage using SQL)\n",
    "\n",
    "Further details can be found in https://spark.apache.org/docs/latest/sql-programming-guide.html  and https://spark.apache.org/docs/latest/api/sql/index.html\n",
    "\n",
    "We can check the reference guide for Structured Query Language (SQL) which includes syntax, semantics, keywords, and examples for common SQL usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Problem formulation\n",
    "\n",
    "This exercise aims to build a recommender system of books, with focus on the recommendation model\n",
    "itself.\n",
    "The functional requirements for the Spark program we want to create are as follows:\n",
    "1. To load the dataset and perform exploratory analysis, then store the information properly cleaned, including as SQL tables.\n",
    "2. To create a recommendation model supported by the ALS algorithm provided by Spark MLlib.\n",
    "3. To pre-compute recommendations and store them in SQL tables.\n",
    "4. To show recommendations.\n",
    "\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "\n",
    "The data we are processing is from the dataset **Book-Crossing**. As stated in the website from where it can be downloaded, http://www2.informatik.uni-freiburg.de/~cziegler/BX/ , the BookCrossing (BX) dataset was collected by Cai-Nicolas Ziegler in a 4-week crawl (August / September 2004) from the Book-Crossing community with kind permission from Ron Hornbaker, CTO of Humankind Systems. It contains 278,858 users (anonymized but with demographic information) providing 1,149,780 ratings (explicit / implicit) about 271,379 books.\n",
    "\n",
    "Alternatively, we can use the command *wget* from the Terminal to download the dataset:\n",
    "\n",
    "    wget http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip\n",
    "\n",
    "\n",
    "The dataset comprises 3 tables, as follows:\n",
    "- **BX-Users**. Contains the users. Note that user IDs ( User-ID ) have been anonymized and map to integers. Demographic data is provided ( Location , Age ) if available. Otherwise, these fields contain NULL-values.\n",
    "- **BX-Books**. Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given ( Book-Title , Book-Author , Year-Of-Publication , Publisher ), obtained from Amazon Web Services. Note that in case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavours ( Image-URL-S , Image-URL-M , Image-URL-L ), i.e., small, medium, large. These URLs point to the Amazon web site.\n",
    "- **BX-Book-Ratings**. Contains the book rating information. Ratings ( Book-Rating ) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0.\n",
    "The columns are separated by ; and all files contain the correspondent header.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to install some packages, e.g. matplotlib\n",
    "\n",
    "# ! pip3 install matplotlib\n",
    "# ! pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:08.158170Z",
     "start_time": "2021-03-07T19:11:07.859222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Some imports \n",
    "\n",
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Useful visualization functions\n",
    "\n",
    "Some functions that we can use to plot data but as Python dataframes.\n",
    "\n",
    "**Disclaimer**: these functions are broadly distributed among users. Further adjustments are needed and/or advisable. Feel free to use your own plotting functions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot(df, xcol, ycol):\n",
    "    sns.lineplot(data=df, x=xcol, y=ycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistogram(df, xcol, huecol, bins):\n",
    "    if huecol:\n",
    "        sns.histplot(data=df, x=xcol, hue=huecol, multiple=\"stack\")\n",
    "    else:\n",
    "        sns.histplot(data=df, x=xcol, bins=bins)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plotScatter(df, xcol, ycol, huecol):\n",
    "    sns.set_theme(style=\"white\")\n",
    "    sns.scatterplot(data=df, x=xcol, y=ycol, hue=huecol)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plotScatterMatrix(df, huecol):\n",
    "    sns.pairplot(data=df, hue=huecol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Collect and label data\n",
    "\n",
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:08.953150Z",
     "start_time": "2021-03-07T19:11:08.185863Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "! pwd \n",
    "! ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 2 BX-Users.csv\n",
    "! tail -n 2 BX-Users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 2 BX-Books.csv\n",
    "! tail -n 2 BX-Books.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 2 BX-Book-Ratings.csv\n",
    "! tail -n 2 BX-Book-Ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:08.961000Z",
     "start_time": "2021-03-07T19:11:08.954809Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# some Spark related imports we will use hereafter\n",
    "\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:12.480883Z",
     "start_time": "2021-03-07T19:11:12.479044Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build a SparkSession instance if one does not exist. Notice that we can only have one per JVM\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Recommender\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:12.476668Z",
     "start_time": "2021-03-07T19:11:08.962435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read the dataset \n",
    "\n",
    "df_raw_users = spark.read.csv(\"BX-Users.csv\", header=\"true\", \n",
    "                              inferSchema=\"true\", sep=\";\")\n",
    "\n",
    "df_raw_books = \n",
    "\n",
    "df_raw_ratings = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:13.028845Z",
     "start_time": "2021-03-07T19:11:12.483086Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check users - schema and count\n",
    "\n",
    "df_raw_users.printSchema()\n",
    "df_raw_users.show(2, vertical=True, truncate=False) \n",
    "num_users = df_raw_users.count()\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check books - schema and count\n",
    "\n",
    "df_raw_books.\n",
    "\n",
    "num_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ratings - schema and count\n",
    "\n",
    "df_raw_ratings.\n",
    "\n",
    "num_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no reasons to drop any column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Evaluate data\n",
    "\n",
    "Let us get some data insight, with some exploratory data analysis based on descriptive statistics and visualizations if advisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some column statistics, one by one, using describe\n",
    "\n",
    "for cl in df_raw_users.columns:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cl in df_raw_books.columns:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cl in df_raw_ratings.columns:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T11:54:16.056821Z",
     "start_time": "2021-03-07T11:54:16.050981Z"
    },
    "hidden": true
   },
   "source": [
    "Following previous understanding, all collected data should be considered as of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Now we have to prepare data in a way that it can be properly used by ML algorithms, which includes selection and extraction of features, as well as dealing with poor data quality if that is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data cleasing\n",
    "\n",
    "We will look at\n",
    "* Data types\n",
    "* Nulls\n",
    "* Extreme values e.g. outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[num_users, df_raw_users.dropna().count()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[num_books, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[num_ratings, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only differences are spotted for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_users.filter(column(\"Age\").isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can conclude that:\n",
    "\n",
    "- User-ID is set as string in users but integer in ratings\n",
    "- Age is set as string in users, with range of values between 0 to null\n",
    "- Year-Of_Publication ranges from 0 to 2050\n",
    "- Book-rating ranges from 0 to 10\n",
    "- Only two observations in users hold null values\n",
    "\n",
    "What can we do now about nulls, data types or extreme values? \n",
    "\n",
    "Recall that if we delete an observation in one table, still consistency among tables has to be preserved. We leave it as exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers: for that, we use summary(), one column by one, using summary\n",
    "\n",
    "for cl in df_raw_users.columns:\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in df_raw_books.columns:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in df_raw_ratings.columns:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_raw_users.select(col(\"Age\")).where(col(\"Age\") == 'NULL').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of NULLs (as string) in the Age column. So, we may\n",
    "- replace the NULLs with the average of others for example (with Imputer) \n",
    "- drop the column Age in case we can live without it \n",
    "- delete the records with NULL in the column Age\n",
    "\n",
    "It is for further discussion!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # We drop column Age now\n",
    "    \n",
    "df_raw_users = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us carry out further checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2004 was when data was collected\n",
    "\n",
    "( df_raw_books\n",
    "     .select('Year-Of-Publication')\n",
    "     .where(col('Year-Of-Publication')>2004)\n",
    "     .distinct()\n",
    "     .orderBy('Year-Of-Publication')\n",
    "     .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior to 1900\n",
    "\n",
    "( df_raw_books\n",
    "     .select('Year-Of-Publication')\n",
    "     \n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot year of publication\n",
    "\n",
    "df_plot = df_raw_books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistogram(df_plot, 'Year-Of-Publication', \"\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop some columns anyway\n",
    "\n",
    "df_raw_books = df_raw_books.drop('Year-Of-Publication', \n",
    "                         'Image-URL-S', 'Image-URL-M', 'Image-URL-L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T11:17:04.469058Z",
     "start_time": "2021-03-07T11:17:04.465458Z"
    },
    "hidden": true
   },
   "source": [
    "## Saving clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we may want to have a smaller dataset just for the purpose of testing locally.\n",
    "But in this case, as mentioned above, consistency among the three tables has to be guaranteed. \n",
    "\n",
    "Let us try to use just the normal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users\n",
    "\n",
    "output_users = \"users.parquet\"\n",
    "df_raw_users.write.mode(\"overwrite\").parquet(output_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Books\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check in the running directory if that was accomplished\n",
    "\n",
    "! ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, save them as persistent tables into Hive metastore\n",
    "\n",
    "Notice\n",
    "- An existing Hive deployment is not necessary to use this feature. Spark will take care of it.\n",
    "- We can create a SQL table from a DataFrame with createOrReplaceTempView command, valid for the session. (there is also the option of global temporary views, to be shared among all sessions till the Spark application terminates)\n",
    "- But with saveAsTable, there will be a pointer to the data in the Hive metastore. So persistent tables will exist even after the Spark program has restarted, as long as connection is maintained to the same metastore.\n",
    "\n",
    "See details in http://spark.apache.org/docs/latest/sql-data-sources.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent tables into Hive metastore\n",
    "\n",
    "df_raw_users.write.mode(\"overwrite\").saveAsTable(\"UsersTable\")\n",
    "df_raw_books.\n",
    "df_raw_ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to be used hereafter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a smaller dataset, once properly built\n",
    "\n",
    "# df_clean_users = ...\n",
    "df_clean_users = df_raw_users\n",
    "df_clean_books = df_raw_books\n",
    "df_clean_ratings = df_raw_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete memory consuming variables that are no longer needed\n",
    "\n",
    "del \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T21:59:55.649596Z",
     "start_time": "2021-03-06T21:59:55.646188Z"
    },
    "hidden": true
   },
   "source": [
    "## Final  overview\n",
    "After establishing the clean data to be used, we should get an overview about what we have achieved, with some statistics and visualizations.\n",
    "\n",
    "**But** \n",
    "\n",
    "we leave it as it is now, because so far there are no significant changes (we just drop columns). Eventually, we could check the ratings and draw some plots, as it is the critical part of the system. You can have a go in that regard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:53:01.240297Z",
     "start_time": "2021-03-06T13:53:01.235639Z"
    },
    "hidden": true
   },
   "source": [
    "## Features transformation\n",
    "\n",
    "As mentioned, ratings are critial here. Recall that, in the dataframe, the schema is User-ID (integer), ISBN (string) and Book-rating (integer). ISBN poses a problem as the ML algorithm requires numbers to process. Hence, we have to convert it to numbers - we will use `StringIndexer` to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringerIndexer for ISBN\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"ISBN\", outputCol=\"ISBN-Index\", handleInvalid=\"keep\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from ratings that are going to be considered in the model\n",
    "\n",
    "user_col = \"User-ID\"\n",
    "item_col = \"ISBN-Index\" \n",
    "rating_col = \"Book-Rating\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T12:46:42.492329Z",
     "start_time": "2021-03-06T12:46:42.487767Z"
    },
    "hidden": true
   },
   "source": [
    "# Select and train model\n",
    "\n",
    "In order to create the recommendation model, we will use the Alternating Least Squares (ALS) algorithm provided by Spark MLlib. See details in http://spark.apache.org/docs/latest/ml-collaborative-filtering.html , as we advise to check the main assumptions the implemented algorithm relies upon. For example, notice that:\n",
    "- it underlies a collaborative filtering strategy;\n",
    "- it aims to fill in the missing entries of a user-item association matrix, in which users and items are described by a small set of latent factors that can be used to predict missing entries. The latent factors are learned by the ALS algorithm.\n",
    "\n",
    "Again, as for data to train the model, the focus is on ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train/test split\n",
    "\n",
    "We will use the standard split 80/20, for the reasons explained in previous lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:31.983392Z",
     "start_time": "2021-03-07T19:11:30.973303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train/test clean ratings split\n",
    "\n",
    "df_train, df_test = \n",
    "\n",
    "# caching data ... but just the training part\n",
    "df_train\n",
    "\n",
    "# print the number of rows in each part\n",
    "print(f\"There are {df_train.count()} rows in the training set and {df_test.count()} in the test set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice** \n",
    "\n",
    "As we did with clean data, we may consider storing the data split into files, should we want to use it elsewhere. \n",
    "This relates to the need of guaranteeing unicity in a different environment. \n",
    "We leave it as it is now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## ALS model\n",
    "\n",
    "Using the `ALS` estimator (the algorithm) to learn from the training data and consequently to build the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:32.955606Z",
     "start_time": "2021-03-07T19:11:32.419126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# note that we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "        \n",
    "        \n",
    "als = ALS(maxIter=5, regParam=0.01, \n",
    "          userCol=user_col, \n",
    "          itemCol=item_col, \n",
    "          ratingCol=rating_col,\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=True\n",
    "         )\n",
    "\n",
    "# if the rating matrix is derived from another source of information\n",
    "# (i.e. it is inferred from other signals), we may set implicitPrefs\n",
    "# to True to get better results (see ALS reference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML pipeline configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:32.970301Z",
     "start_time": "2021-03-07T19:11:32.967223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The pipeline holds two stages set above\n",
    "\n",
    "# As we will see below, we are going to use it just for evaluation purposes\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, als])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "Get the model (as transformer) by fitting the pipeline to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model\n",
    "\n",
    "Let us evaluate the ALS model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "It is time to apply the model built to test data. Again, we will use the pipeline set above. Notice that, since the pipeline model is a transformer, we can easily apply it to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:11:33.280981Z",
     "start_time": "2021-03-07T19:11:32.971571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on test data and show values of columns of interest\n",
    "\n",
    "df_prediction = pipeline_model.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking its schema and content\n",
    "\n",
    "df_prediction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions ordered by USER-ID\n",
    "\n",
    "df_prediction.orderBy(\"User-ID\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions ordered by ISBN-Index\n",
    "\n",
    "df_prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "Let us use an evaluator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                labelCol=rating_col,\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(df_prediction)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save the pipeline for further use should it be required\n",
    "\n",
    "pipeline.save(\"pipeline-ALS\")\n",
    "\n",
    "# later on, it can be loaded anywhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -la pipeline-ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-computing recommendations and storing as persistent tables\n",
    "\n",
    "The `ALS` algorithm provides some functions to get recommendations directly. \n",
    "\n",
    "Although we can achieve results if working with predictions after the pipeline set (see below), we will take advantage of such methods directly. We should emphasize that, as it stands, we will not be using the pipeline for this task.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "+-------+----------+-----------+----------+-------------+\n",
    "|User-ID|ISBN      |Book-Rating|ISBN-Index|prediction   |\n",
    "+-------+----------+-----------+----------+-------------+\n",
    "|30261  |0385504209|0          |2.0       |0.04549066   |\n",
    "|3363   |0385504209|0          |2.0       |0.03916065   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking with training data for the sake of example\n",
    "\n",
    "df_train_indexed = indexer.fit(df_train).transform(df_train)\n",
    "model = als.fit(df_train_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distinct users and books\n",
    "\n",
    "#user_col = \"User-ID\"\n",
    "#item_col = \"ISBN-Index\" \n",
    "#rating_col = \"Book-Rating\"\n",
    "\n",
    "users = df_train_indexed.select(als.getUserCol()).distinct()\n",
    "\n",
    "books = df_train_indexed.select(als.getItemCol()).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[users.count(), books.count()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top book recommendations for users\n",
    "\n",
    "top_n_books = 2\n",
    "user_recs = model.recommendForAllUsers(top_n_books)\n",
    "\n",
    "# Generate top book recommendations for a specified set of users\n",
    "\n",
    "# subset_users = users.limit(5)\n",
    "# user_subset_recs = model.recommendForUserSubset(subset_users, top_n_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recs.show(truncate=False)\n",
    "\n",
    "# user_subset_recs.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top user recommendations for each book\n",
    "\n",
    "top_n_users = 2\n",
    "book_recs = model.recommendForAllItems(top_n_users)\n",
    "\n",
    "# Generate top user recommendations for a specified set of books\n",
    "\n",
    "# subset_books = books.limit(5)\n",
    "# book_subset_recs = model.recommendForItemSubset(subset_books, top_n_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_recs.show(truncate=False)\n",
    "\n",
    "# book_subset_recs.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recommendations as persistent tables into the Hive metastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " user_recs.write.mode(\"overwrite\").saveAsTable(\"UserRecommendationsTable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_recs.write.mode(\"overwrite\").saveAsTable(\"BookRecommendationsTable\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It looks like we had a problem storing array<struct<ISBN-Index:int,rating:float>>\n",
    "\n",
    "Exercise: how to sort it out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring results\n",
    "1. Given a user, shows the recommended list of books.\n",
    "2. Given a book, shows the list of users who might be interested on.\n",
    "\n",
    "We are going to use Spark SQL tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user to explore\n",
    "\n",
    "user = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book to explore\n",
    "\n",
    "book = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us check the SQL tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register information about users as a SQL temporary view\n",
    "\n",
    "df_clean_users.createOrReplaceTempView(\"users\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register information about books as a SQL temporary view\n",
    "\n",
    "df_clean_books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.catalog.listDatabases())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " spark.catalog.listTables(dbName=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use managed tables\n",
    "\n",
    "spark.sql(\"USE default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listColumns('bookstable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " spark.sql(\"SELECT * FROM users\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " spark.sql(\"SELECT * FROM books\").show(10, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"The recommended books for user \" + str(user) + \" are: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leave it as exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"The users who might be interested on the book \" + str(book) + \" are: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We leave it as exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune model\n",
    "\n",
    "We can improve the model. For example, by carrying out better data cleasing operations and take into consideration efficiency issues. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Additional exercise\n",
    "\n",
    "Given the current status of this notebook, redo its content such that major tasks are split into \n",
    "various notebooks, ou Python modules. \n",
    "The purpose is to modularize code having in mind the setup of a real recommender system. That is:\n",
    "- A downloader module, focussing on downloading data, cleasing it, and then storing it in a data store.\n",
    "- A recommender module, to create a recommendation module and to pre-compute recommendations in order to save them a data store.\n",
    "- A recommender server, to retrieve recommendations upon queries made to the data store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Learning Spark - Lightning-Fast Data Analytics, 2nd Ed. J. Damji, B. Wenig, T. Das, and D. Lee. O'Reilly, 2020\n",
    "* Spark: The Definitive Guide - Big Data Processing Made Simple, 1st Ed. B. Chambers and M. Zaharia. O'Reilly, 2018\n",
    "* http://spark.apache.org/docs/latest/ml-guide.html\n",
    "* https://docs.python.org/3/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249px",
    "width": "332px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.98px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
